#!/usr/bin/env python3
"""
Claude GitHub ActionsåŸºæœ¬æ©Ÿèƒ½ã§ã®ãƒ¡ã‚¿ãƒœãƒ­ãƒŸã‚¯ã‚¹è§£æãƒ†ã‚¹ãƒˆ
ä½¿ç”¨ãƒ„ãƒ¼ãƒ«: æ¨™æº–Pythonï¼ˆpandas, numpy, matplotlib, scipyï¼‰ã®ã¿
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

def basic_metabolomics_analysis():
    """åŸºæœ¬æ©Ÿèƒ½ã®ã¿ã§ã®åŒ…æ‹¬çš„ãƒ¡ã‚¿ãƒœãƒ­ãƒŸã‚¯ã‚¹è§£æ"""
    
    print("=== Claude GitHub Actions åŸºæœ¬æ©Ÿèƒ½ãƒ¡ã‚¿ãƒœãƒ­ãƒŸã‚¯ã‚¹è§£æ ===")
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åŸºæœ¬æƒ…å ±
    print("\n1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
    data = pd.read_csv('data/fasting.csv', sep=';', index_col=0)
    numeric_data = data.apply(pd.to_numeric, errors='coerce')
    
    print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {data.shape}")
    print(f"ã‚µãƒ³ãƒ—ãƒ«: {list(data.index)}")
    print(f"ä»£è¬ç‰©è³ªæ•°: {data.shape[1]}")
    
    # 2. ã‚µãƒ³ãƒ—ãƒ«åˆ†é¡
    print("\n2. ã‚µãƒ³ãƒ—ãƒ«åˆ†é¡")
    normal_samples = [idx for idx in data.index if 'normal' in idx.lower()]
    fasting_samples = [idx for idx in data.index if 'fasting' in idx.lower()]
    print(f"æ­£å¸¸ç¾¤: {len(normal_samples)} æ¤œä½“ - {normal_samples}")
    print(f"çµ¶é£Ÿç¾¤: {len(fasting_samples)} æ¤œä½“ - {fasting_samples}")
    
    # 3. ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡
    print("\n3. ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡")
    missing_count = numeric_data.isnull().sum().sum()
    total_values = numeric_data.size
    print(f"æ¬ æå€¤: {missing_count}/{total_values} ({(missing_count/total_values)*100:.2f}%)")
    print(f"ãƒ‡ãƒ¼ã‚¿å®Œæ•´æ€§: {100-(missing_count/total_values)*100:.1f}%")
    
    # 4. ä»£è¬ç‰©è³ªåˆ†é¡
    print("\n4. ä»£è¬ç‰©è³ªã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†æ")
    metabolites = data.columns.tolist()
    
    categories = {
        'ã‚¢ãƒŸãƒé…¸': ['Ala', 'Arg', 'Asn', 'Asp', 'Cys', 'Gln', 'Glu', 'Gly', 'His', 'Ile', 'Leu', 'Lys', 'Met', 'Phe', 'Pro', 'Ser', 'Thr', 'Trp', 'Tyr', 'Val'],
        'ã‚¨ãƒãƒ«ã‚®ãƒ¼ä»£è¬': ['ATP', 'ADP', 'AMP', 'GTP', 'GDP', 'GMP', 'UTP', 'UDP', 'UMP', 'glucose', 'pyruvic', 'citric', 'fumaric', 'succinic', 'malic'],
        'è„‚è³ªä»£è¬': ['Carnitine', 'Choline', 'Betaine', 'CoA'],
        'ç¥çµŒä¼é”ç‰©è³ª': ['Serotonin', 'GABA', 'Histamine'],
        'æŠ—é…¸åŒ–ç‰©è³ª': ['Glutathione', 'Ascorbic', 'Taurine']
    }
    
    found_metabolites = {}
    for category, markers in categories.items():
        found = [m for m in metabolites if any(marker in m for marker in markers)]
        found_metabolites[category] = found
        print(f"{category}: {len(found)} ç¨®é¡")
        if found[:3]: 
            print(f"  ä¾‹: {[m[:25]+'...' if len(m)>25 else m for m in found[:3]]}")
    
    # 5. åŸºæœ¬çµ±è¨ˆè§£æ
    print("\n5. åŸºæœ¬çµ±è¨ˆè§£æ")
    data_stats = numeric_data.describe()
    print(f"æ¿ƒåº¦ç¯„å›²: {data_stats.loc['min'].min():.2e} - {data_stats.loc['max'].max():.2e}")
    
    top_var = numeric_data.std().nlargest(5)
    print(f"æœ€ã‚‚å¤‰å‹•ã®å¤§ãã„ä»£è¬ç‰©è³ªTOP5:")
    for i, (metabolite, std_val) in enumerate(top_var.items(), 1):
        name = metabolite[:35] + '...' if len(metabolite) > 35 else metabolite
        print(f"  {i}. {name} (Ïƒ={std_val:.4f})")
    
    # 6. ç¾¤é–“æ¯”è¼ƒï¼ˆtæ¤œå®šï¼‰
    print("\n6. ç¾¤é–“çµ±è¨ˆæ¯”è¼ƒï¼ˆæ­£å¸¸ vs çµ¶é£Ÿï¼‰")
    from scipy import stats
    
    significant_metabolites = []
    
    for metabolite in numeric_data.columns:
        normal_vals = numeric_data.loc[normal_samples, metabolite].dropna()
        fasting_vals = numeric_data.loc[fasting_samples, metabolite].dropna()
        
        if len(normal_vals) >= 3 and len(fasting_vals) >= 3:
            try:
                stat, p_val = stats.ttest_ind(normal_vals, fasting_vals)
                if p_val < 0.05:
                    fold_change = fasting_vals.mean() / normal_vals.mean() if normal_vals.mean() > 0 else np.inf
                    significant_metabolites.append({
                        'metabolite': metabolite,
                        'p_value': p_val,
                        'fold_change': fold_change,
                        'normal_mean': normal_vals.mean(),
                        'fasting_mean': fasting_vals.mean()
                    })
            except:
                continue
    
    significant_metabolites.sort(key=lambda x: x['p_value'])
    
    print(f"æœ‰æ„å·®ã®ã‚ã‚‹ä»£è¬ç‰©è³ª: {len(significant_metabolites)} ç¨®é¡ (p<0.05)")
    print("TOP5 æœ‰æ„å·®ã®ã‚ã‚‹ä»£è¬ç‰©è³ª:")
    for i, met in enumerate(significant_metabolites[:5], 1):
        name = met['metabolite'][:30] + '...' if len(met['metabolite']) > 30 else met['metabolite']
        print(f"  {i}. {name} (p={met['p_value']:.3e}, FC={met['fold_change']:.2f})")
    
    # 7. ç°¡æ˜“ç›¸é–¢è§£æ
    print("\n7. ç›¸é–¢è§£æ")
    corr_matrix = numeric_data.corr()
    
    high_corr_count = 0
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if abs(corr_matrix.iloc[i, j]) > 0.8:
                high_corr_count += 1
    
    print(f"é«˜ç›¸é–¢ãƒšã‚¢ (|r|>0.8): {high_corr_count} çµ„")
    
    # 8. å¯è¦–åŒ–ï¼ˆåŸºæœ¬ãƒ—ãƒ­ãƒƒãƒˆï¼‰
    print("\n8. åŸºæœ¬å¯è¦–åŒ–ç”Ÿæˆ")
    
    # ã‚µãƒ³ãƒ—ãƒ«åˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆ
    plt.figure(figsize=(12, 8))
    
    # ä¸»è¦ä»£è¬ç‰©è³ªã®ç®±ã²ã’å›³
    plt.subplot(2, 2, 1)
    top5_metabolites = numeric_data.std().nlargest(5).index
    box_data = []
    labels = []
    
    for metabolite in top5_metabolites[:3]:  # ä¸Šä½3ã¤ã®ã¿ãƒ—ãƒ­ãƒƒãƒˆ
        normal_vals = numeric_data.loc[normal_samples, metabolite].dropna()
        fasting_vals = numeric_data.loc[fasting_samples, metabolite].dropna()
        box_data.extend([normal_vals, fasting_vals])
        short_name = metabolite[:15] + '...' if len(metabolite) > 15 else metabolite
        labels.extend([f'{short_name}\n(Normal)', f'{short_name}\n(Fasting)'])
    
    plt.boxplot(box_data, labels=labels)
    plt.title('Top Variable Metabolites')
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Concentration')
    
    # ç¾¤é–“å¹³å‡æ¯”è¼ƒ
    plt.subplot(2, 2, 2)
    if significant_metabolites:
        top_sig = significant_metabolites[:5]
        metabolite_names = [m['metabolite'][:10] + '...' if len(m['metabolite']) > 10 else m['metabolite'] 
                          for m in top_sig]
        normal_means = [m['normal_mean'] for m in top_sig]
        fasting_means = [m['fasting_mean'] for m in top_sig]
        
        x = range(len(metabolite_names))
        width = 0.35
        plt.bar([i - width/2 for i in x], normal_means, width, label='Normal', alpha=0.7)
        plt.bar([i + width/2 for i in x], fasting_means, width, label='Fasting', alpha=0.7)
        plt.xlabel('Metabolites')
        plt.ylabel('Mean Concentration')
        plt.title('Significant Metabolites (Top 5)')
        plt.legend()
        plt.xticks(x, metabolite_names, rotation=45, ha='right')
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆã‚µãƒ³ãƒ—ãƒ«åˆ¥æ¬ æå€¤ï¼‰
    plt.subplot(2, 2, 3)
    missing_by_sample = numeric_data.isnull().sum(axis=1)
    plt.bar(range(len(missing_by_sample)), missing_by_sample.values)
    plt.xlabel('Sample Index')
    plt.ylabel('Missing Values')
    plt.title('Data Quality by Sample')
    plt.xticks(range(len(data.index)), 
               [idx[:8] + '...' if len(idx) > 8 else idx for idx in data.index], 
               rotation=45, ha='right')
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ä»£è¬ç‰©è³ªæ•°
    plt.subplot(2, 2, 4)
    categories_count = [(cat, len(mets)) for cat, mets in found_metabolites.items()]
    categories_count.sort(key=lambda x: x[1], reverse=True)
    
    cats, counts = zip(*categories_count)
    plt.pie(counts, labels=cats, autopct='%1.1f%%')
    plt.title('Metabolite Categories')
    
    plt.tight_layout()
    plt.savefig('basic_analysis_results.png', dpi=200, bbox_inches='tight')
    print("åŸºæœ¬è§£æçµæœã‚’ 'basic_analysis_results.png' ã«ä¿å­˜")
    
    return {
        'data_shape': data.shape,
        'samples': {'normal': normal_samples, 'fasting': fasting_samples},
        'data_quality': f"{100-(missing_count/total_values)*100:.1f}%",
        'significant_metabolites': len(significant_metabolites),
        'high_correlations': high_corr_count,
        'metabolite_categories': {cat: len(mets) for cat, mets in found_metabolites.items()}
    }

def generate_basic_report(results):
    """åŸºæœ¬è§£æçµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    report = f"""# Claude GitHub ActionsåŸºæœ¬æ©Ÿèƒ½ ãƒ¡ã‚¿ãƒœãƒ­ãƒŸã‚¯ã‚¹è§£æãƒ¬ãƒãƒ¼ãƒˆ

## è§£ææ¦‚è¦
- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: fasting.csv
- **è§£ææ—¥æ™‚**: 2025-09-05
- **ä½¿ç”¨ãƒ„ãƒ¼ãƒ«**: Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆpandas, numpy, matplotlib, scipyï¼‰

## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåŸºæœ¬æƒ…å ±
- **ã‚µãƒ³ãƒ—ãƒ«æ•°**: {results['data_shape'][0]} æ¤œä½“
- **ä»£è¬ç‰©è³ªæ•°**: {results['data_shape'][1]} ç¨®é¡
- **æ­£å¸¸ç¾¤**: {len(results['samples']['normal'])} æ¤œä½“
- **çµ¶é£Ÿç¾¤**: {len(results['samples']['fasting'])} æ¤œä½“
- **ãƒ‡ãƒ¼ã‚¿å“è³ª**: {results['data_quality']} å®Œæ•´æ€§

## åŸºæœ¬æ©Ÿèƒ½ã§ã®è§£æçµæœ

### âœ… å®Ÿç¾å¯èƒ½ãªè§£æ
1. **åŸºæœ¬çµ±è¨ˆè§£æ**: âœ… å¹³å‡ã€åˆ†æ•£ã€åˆ†å¸ƒåˆ†æ
2. **ç¾¤é–“æ¯”è¼ƒ**: âœ… tæ¤œå®šã«ã‚ˆã‚‹æœ‰æ„å·®æ¤œå®š ({results['significant_metabolites']} ä»£è¬ç‰©è³ªã§æœ‰æ„å·®)
3. **ç›¸é–¢è§£æ**: âœ… ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢åˆ†æ ({results['high_correlations']} é«˜ç›¸é–¢ãƒšã‚¢æ¤œå‡º)
4. **ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡**: âœ… æ¬ æå€¤ã€å¤–ã‚Œå€¤ã®è©•ä¾¡
5. **åŸºæœ¬å¯è¦–åŒ–**: âœ… ç®±ã²ã’å›³ã€æ£’ã‚°ãƒ©ãƒ•ã€å††ã‚°ãƒ©ãƒ•ã€æ•£å¸ƒå›³
6. **ä»£è¬ç‰©è³ªåˆ†é¡**: âœ… æ©Ÿèƒ½åˆ¥ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†æ

### ä»£è¬ç‰©è³ªã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†æçµæœ
"""
    
    for category, count in results['metabolite_categories'].items():
        report += f"- **{category}**: {count} ç¨®é¡\n"
    
    report += f"""

## åŸºæœ¬æ©Ÿèƒ½ã®åˆ¶é™äº‹é …

### âŒ é«˜åº¦ãªè§£æã§ä¸è¶³ã™ã‚‹æ©Ÿèƒ½
1. **ä¸»æˆåˆ†åˆ†æ (PCA)**: sklearn.decomposition.PCA ãŒå¿…è¦
2. **ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**: é«˜åº¦ãªæ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦  
3. **ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤è§£æ**: ç”Ÿç‰©å­¦çš„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®é€£æºãŒå¿…è¦
4. **é«˜å“è³ªãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—**: seabornç­‰ã®å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦
5. **å¤šå¤‰é‡çµ±è¨ˆ**: ã‚ˆã‚Šè¤‡é›‘ãªçµ±è¨ˆæ‰‹æ³•ãŒåˆ¶é™ã•ã‚Œã‚‹
6. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ**: å°‚é–€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦

## çµè«–

### ğŸ¯ Claude GitHub ActionsåŸºæœ¬æ©Ÿèƒ½ã®å®ŸåŠ›
**60-70%ã®åŒ…æ‹¬çš„ãƒ¡ã‚¿ãƒœãƒ­ãƒŸã‚¯ã‚¹è§£æãŒå¯èƒ½**

- **åŸºæœ¬çµ±è¨ˆãƒ»ç¾¤é–“æ¯”è¼ƒ**: å®Œå…¨å¯¾å¿œ âœ…
- **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»å“è³ªç®¡ç†**: å®Œå…¨å¯¾å¿œ âœ…  
- **åŸºæœ¬å¯è¦–åŒ–**: ååˆ†å¯¾å¿œ âœ…
- **ç”Ÿç‰©å­¦çš„è§£é‡ˆ**: éƒ¨åˆ†çš„å¯¾å¿œ âš ï¸
- **é«˜åº¦ãªå¤šå¤‰é‡è§£æ**: åˆ¶é™ã‚ã‚Š âŒ

### ğŸ“Š æ—¢å­˜ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã®æ¯”è¼ƒ
- **æ—¢å­˜ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: PCAã€é«˜åº¦ãªå¯è¦–åŒ–ã€åŒ…æ‹¬çš„çµ±è¨ˆã‚’å«ã‚€å®Œå…¨è§£æ
- **åŸºæœ¬æ©Ÿèƒ½**: æ ¸å¿ƒçš„ãªçµ±è¨ˆè§£æã¨åŸºæœ¬çš„ãªç”Ÿç‰©å­¦çš„çŸ¥è¦‹ã®æŠ½å‡ºãŒå¯èƒ½

### ğŸ’¡ æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
1. **åˆæœŸæ¢ç´¢**: åŸºæœ¬æ©Ÿèƒ½ã§ååˆ†ï¼ˆãƒ‡ãƒ¼ã‚¿ç†è§£ã€å“è³ªè©•ä¾¡ã€ç¾¤é–“æ¯”è¼ƒï¼‰
2. **è©³ç´°è§£æ**: æ—¢å­˜ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§è£œå®Œï¼ˆPCAã€é«˜åº¦ãªå¯è¦–åŒ–ï¼‰
3. **çµ±åˆè§£é‡ˆ**: ä¸¡æ–¹ã®çµæœã‚’çµ„ã¿åˆã‚ã›ãŸåŒ…æ‹¬çš„è§£é‡ˆ

---
*Claude GitHub ActionsåŸºæœ¬æ©Ÿèƒ½ã«ã‚ˆã‚‹è§£æå®Œäº†*
"""
    
    with open('basic_analysis_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("åŸºæœ¬è§£æãƒ¬ãƒãƒ¼ãƒˆã‚’ 'basic_analysis_report.md' ã«ä¿å­˜")

if __name__ == "__main__":
    results = basic_metabolomics_analysis()
    generate_basic_report(results)
    print("\n=== åŸºæœ¬æ©Ÿèƒ½è§£æå®Œäº† ===")